<!DOCTYPE html PUBLIC "-//w3c//dtd html 4.0 transitional//en">
<!-- saved from url=(0036)http://www.nada.kth.se/cvap/actions/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
   
   <meta name="GENERATOR" content="Mozilla/4.75 [en] (X11; U; SunOS 5.6 sun4u) [Netscape]">
   <title>Single Pixel Camera Dataset</title>
<!-- NADA MHTML preprocessor version C    -->
<!-- Ändra inte i denna fil!  -->
<!-- Do not edit this file!   -->
<!-- Instead, change the corresponding .mhtml file  -->
<!-- Then make the .html file with the NADA command "mhtml file" -->
<!-- The NADA command "local-info mhtml" gives help (in Swedish)  -->
<!-- *** Ändra/kolla värden här *** -->
<link rev="made" href="mailto:jianwang.cmu@gmail.com">
<style type="text/css">
.auto-style1 {
	font-size: xx-small;
}
</style>
</head>
<body bgcolor="#FFFFFF">


<h1><center>Single pixel camera dataset</center></h1>

<font size="+2">Hardware</font> <br>
<ul>
We built a single-pixel camera using a DLP V7000 digital micromirror device (DMD), a Thorlabs PDA100A photodetector and a Digilent Analog Discovery analog-to-digital converter. 
The DMD has 1024 * 768 micromirrors and can change the mirror configurations at 22.7 kHz. We operate DMD at this speed and our SPC
can obtain 22.7k measurements per second.
<br>
For obtaining compressive measurements, we use a permuted Hadamard matrix as the measurement matrix. For an N * N image (N = 64 or 128 in this dataset), we first generate an N^2 * N^2 column-permuted Hadamard matrix. 
Each row of this matrix is reshaped into an N * N matrix and then upsampled to the 1024 * 768 mircomirror array (e.g. when N = 64,  every block of (1024 / 64) * (768 / 64) = 16 * 12 micromirrors acts as one mirror). 
The Hadamard matrix is composed of +1/-1 measurements but the DMD can only implement a 0/1 measurement. To resolve this mismatch, we first change all "-1" to  "0" in the measurement matrix, 
take the measurements, and then subtract all "1" measurement from all measurements doubled, e.g. [1 -1 1 -1] = [1 0 1 0] * 2 - [1 1 1 1]. In practice, we can simply subtract the median of all 
measurements.
<br>
Below is a photo of our hardware. The shaded area is another compressive sensing camera LiSens. We built SPC to compare it to LiSens.</ul>

<p></p><center>
<img src="./index_files/SPC.png" align="TOP" height="232" width="377"></center>
<br>


<font size="+2">Static objects</font> <br>
<ul>
This dataset contains 20 objects with four different backgrounds. It can be used for testing compressive sensing recontruction and object recognition algorithms.
The resolution for each object has two versions, 64*64 and 128*128. The fourth background is also included. 
Download measurement matrix and raw data here <a href="https://www.dropbox.com/sh/zmipodcmzoq302v/AAB0udSIr5bX0P00tHidZmEqa?dl=0"> staticObjects.zip [63.4MB]</a>.
</ul>

<p></p><center><img src="./index_files/objects/1.png" align="TOP">&nbsp;&nbsp;
<img src="./index_files/objects/2.png" align="TOP">&nbsp;&nbsp;
<img src="./index_files/objects/3.png" align="TOP">&nbsp;&nbsp;
<img src="./index_files/objects/4.png" align="TOP">
</center>
<br>

<font size="+2">Dynamic scenes 1</font> <br>
<ul>
This dataset contains 14 video clips of movement. It can be used for testing compressive sensing video recontruction and human action recognition algorithms.
each with 5 actions (one hand waving, two hand waving, boxing, bending, and squarting)
Each video contains action of at least two cycles.For human action recognition, the variations include: occlusion, changing light, changing object distance, etc. See the GIF files below. 
The resolution is 64 * 64. The first video is background only. 
Download measurement matrix and raw data here <a href="https://www.dropbox.com/sh/7yr8i7876z7te2y/AAAycwAlD4StePIzQ5g4WHFaa?dl=0"> dynamic1.zip [44.2MB]</a>.
</ul>

<p></p><center>
<img src="./index_files/dynamic1/objectTracking_0.gif" align="TOP">
<img src="./index_files/dynamic1/objectTracking_1.gif" align="TOP">
<img src="./index_files/dynamic1/objectTracking_2.gif" align="TOP">
<img src="./index_files/dynamic1/objectTracking_3.gif" align="TOP">
<img src="./index_files/dynamic1/objectTracking_4.gif" align="TOP">
<img src="./index_files/dynamic1/objectTracking_5.gif" align="TOP">
<img src="./index_files/dynamic1/objectTracking_6.gif" align="TOP"><br>
<br class="auto-style1" style="font-size: 4px"> 
<img src="./index_files/dynamic1/objectTracking_7.gif" align="TOP">
<img src="./index_files/dynamic1/objectTracking_8.gif" align="TOP">
<img src="./index_files/dynamic1/objectTracking_9.gif" align="TOP">
<img src="./index_files/dynamic1/objectTracking_10.gif" align="TOP">
<img src="./index_files/dynamic1/objectTracking_11.gif" align="TOP">
<img src="./index_files/dynamic1/objectTracking_12.gif" align="TOP">
<img src="./index_files/dynamic1/objectTracking_13.gif" align="TOP">
</center>
<br>

<font size="+2">Dynamic scenes 2</font> <br>
<ul>This dataset contains 55 video clips of human movement. It can be used for testing compressive sensing video recontruction and object tracking algorithms.
It includes 11 people, each with 5 actions (one hand waving, two hands waving, boxing, bending, and squarting). Each video contains action of at least two cycles.
See the GIF files below. The resolution is 64 * 64. Download measurement matrix and raw data here <a href="https://www.dropbox.com/sh/gtjl4kqteedjom8/AACgFId7g608AXyORW2cpVIMa?dl=0"> dynamic2.zip [100MB]</a>.
</ul>

<p></p><center>
<img src="./index_files/dynamic2/human_1.gif" align="TOP">
<img src="./index_files/dynamic2/human_2.gif" align="TOP">
<img src="./index_files/dynamic2/human_3.gif" align="TOP">
<img src="./index_files/dynamic2/human_4.gif" align="TOP">
<img src="./index_files/dynamic2/human_5.gif" align="TOP">
<img src="./index_files/dynamic2/human_6.gif" align="TOP">
<img src="./index_files/dynamic2/human_7.gif" align="TOP">
<img src="./index_files/dynamic2/human_8.gif" align="TOP">
<img src="./index_files/dynamic2/human_9.gif" align="TOP">
<img src="./index_files/dynamic2/human_10.gif" align="TOP">
<img src="./index_files/dynamic2/human_11.gif" align="TOP"><br>
<br class="auto-style1" style="font-size: 4px"> 
<img src="./index_files/dynamic2/human_12.gif" align="TOP">
<img src="./index_files/dynamic2/human_13.gif" align="TOP">
<img src="./index_files/dynamic2/human_14.gif" align="TOP">
<img src="./index_files/dynamic2/human_15.gif" align="TOP">
<img src="./index_files/dynamic2/human_16.gif" align="TOP">
<img src="./index_files/dynamic2/human_17.gif" align="TOP">
<img src="./index_files/dynamic2/human_18.gif" align="TOP">
<img src="./index_files/dynamic2/human_19.gif" align="TOP">
<img src="./index_files/dynamic2/human_20.gif" align="TOP">
<img src="./index_files/dynamic2/human_21.gif" align="TOP">
<img src="./index_files/dynamic2/human_22.gif" align="TOP"><br>
<br class="auto-style1" style="font-size: 4px"> 
<img src="./index_files/dynamic2/human_23.gif" align="TOP">
<img src="./index_files/dynamic2/human_24.gif" align="TOP">
<img src="./index_files/dynamic2/human_25.gif" align="TOP">
<img src="./index_files/dynamic2/human_26.gif" align="TOP">
<img src="./index_files/dynamic2/human_27.gif" align="TOP">
<img src="./index_files/dynamic2/human_28.gif" align="TOP">
<img src="./index_files/dynamic2/human_29.gif" align="TOP">
<img src="./index_files/dynamic2/human_30.gif" align="TOP">
<img src="./index_files/dynamic2/human_31.gif" align="TOP">
<img src="./index_files/dynamic2/human_32.gif" align="TOP">
<img src="./index_files/dynamic2/human_33.gif" align="TOP"><br>
<br class="auto-style1" style="font-size: 4px"> 
<img src="./index_files/dynamic2/human_34.gif" align="TOP">
<img src="./index_files/dynamic2/human_35.gif" align="TOP">
<img src="./index_files/dynamic2/human_36.gif" align="TOP">
<img src="./index_files/dynamic2/human_37.gif" align="TOP">
<img src="./index_files/dynamic2/human_38.gif" align="TOP">
<img src="./index_files/dynamic2/human_39.gif" align="TOP">
<img src="./index_files/dynamic2/human_40.gif" align="TOP">
<img src="./index_files/dynamic2/human_41.gif" align="TOP">
<img src="./index_files/dynamic2/human_42.gif" align="TOP">
<img src="./index_files/dynamic2/human_43.gif" align="TOP">
<img src="./index_files/dynamic2/human_44.gif" align="TOP"><br>
<br class="auto-style1" style="font-size: 4px"> 
<img src="./index_files/dynamic2/human_45.gif" align="TOP">
<img src="./index_files/dynamic2/human_46.gif" align="TOP">
<img src="./index_files/dynamic2/human_47.gif" align="TOP">
<img src="./index_files/dynamic2/human_48.gif" align="TOP">
<img src="./index_files/dynamic2/human_49.gif" align="TOP">
<img src="./index_files/dynamic2/human_50.gif" align="TOP">
<img src="./index_files/dynamic2/human_51.gif" align="TOP">
<img src="./index_files/dynamic2/human_52.gif" align="TOP">
<img src="./index_files/dynamic2/human_53.gif" align="TOP">
<img src="./index_files/dynamic2/human_54.gif" align="TOP">
<img src="./index_files/dynamic2/human_55.gif" align="TOP"><br>
</center>
<br>

<font size="+2">Related publications</font>

<ul>
<b>"LiSens — A Scalable Architecture for Video Compressive Sensing"</b>,<br>
   Jian Wang, Mohit Gupta, and Aswin C. Sankaranarayanan;
   in <i> ICCP2015 </i>
   [<a href="http://imagesci.ece.cmu.edu/files/paper/2015/LiSens_ICCP15.pdf">Paper</a>]
</ul>

<ul>
<b>"Reconstruction Free Inference from Compressive Measurements"</b>,<br>
   Suhas Lohit, Kuldeep Kulkarni, Pavan Turaga, 
   Jian Wang and Aswin C. Sankaranarayanan
   in <i> CCD 2015</i>
   [<a href="http://imagesci.ece.cmu.edu/files/paper/2015/ccd2015submission.pdf">Paper</a>]
</ul>

<br>
<font size="+2">Contact</font> <br>

<ul>
<a href="https://jianwang-cmu.github.io/"> Jian Wang</a> email: jianwang.cmu -at- gmail .dot. com
<br>
<a href="https://kuldeepkulkarni.github.io/"> Kuldeep Kulkarni</a> 
<br>
<a href="https://users.ece.cmu.edu/~saswin/"> Aswin Sankaranarayanan</a> email: saswin -at- andrew .dot. cmu .dot. edu
</ul>


</body></html>
